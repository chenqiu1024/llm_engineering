{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: Generative AI can generate high-quality content such as images, videos, music, and text, which can be used for marketing, advertising, or entertainment purposes.\n",
      "2. **Personalization**: Generative AI can analyze customer data and behavior to create personalized product recommendations, offers, and experiences that are tailored to individual needs and preferences.\n",
      "3. **Product Design**: Generative AI can design new products, packaging, and branding materials by analyzing trends, consumer feedback, and market data.\n",
      "4. **Marketing Automation**: Generative AI can automate marketing campaigns, such as generating social media posts, email newsletters, and content ads that are tailored to specific audiences.\n",
      "5. **Data Analysis**: Generative AI can analyze large datasets to identify patterns, predict trends, and make recommendations for business improvement.\n",
      "6. **Customer Service**: Generative AI-powered chatbots can provide 24/7 customer support, answer common questions, and route complex issues to human representatives.\n",
      "7. **Supply Chain Optimization**: Generative AI can analyze logistics data to optimize supply chain operations, predict demand, and reduce costs.\n",
      "8. **Financial Analysis**: Generative AI can analyze financial data to identify trends, predict market movements, and make investment recommendations.\n",
      "9. **Creative Writing**: Generative AI can assist writers with content generation, such as article writing, blog posts, and social media content.\n",
      "10. **Cybersecurity**: Generative AI can help detect and respond to cyber threats by analyzing network traffic, identifying patterns, and predicting potential attacks.\n",
      "\n",
      "Some specific business applications of Generative AI include:\n",
      "\n",
      "* **Generative Design for Product Development**: Companies like Nike and Louis Vuitton use Generative AI to design new products, packaging, and branding materials.\n",
      "* **AI-powered Sales**: Companies like Salesforce and HubSpot use Generative AI to analyze customer data and behavior, generating personalized product recommendations and sales forecasts.\n",
      "* **Automated Content Generation**: Companies like The New York Times and CNN use Generative AI to generate news articles, social media posts, and other content.\n",
      "* **Predictive Maintenance**: Companies like GE and Siemens use Generative AI to analyze equipment data and predict maintenance needs, reducing downtime and costs.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses in various industries.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Generation**: Generative AI can be used to generate high-quality content such as articles, social media posts, product descriptions, and more. This can help businesses save time and resources on content creation.\n",
      "2. **Chatbots and Virtual Assistants**: Generative AI can power chatbots and virtual assistants that provide customer support, answer frequently asked questions, and offer personalized recommendations.\n",
      "3. **Product Design and Development**: Generative AI can be used to design new products, such as 3D models, user interfaces, and more. This can help businesses accelerate product development and reduce costs.\n",
      "4. **Marketing and Advertising**: Generative AI can be used to generate targeted advertisements, social media posts, and influencer content that resonates with specific audience segments.\n",
      "5. **Data Analysis and Visualization**: Generative AI can be used to analyze and visualize large datasets, identifying patterns and trends that can inform business decisions.\n",
      "6. **Customer Segmentation**: Generative AI can be used to segment customers based on their behavior, preferences, and demographics, helping businesses tailor their marketing efforts and improve customer engagement.\n",
      "7. **Predictive Maintenance**: Generative AI can be used to predict equipment failures and maintenance needs, reducing downtime and improving overall operational efficiency.\n",
      "8. **Speech Synthesis**: Generative AI can be used to generate high-quality speech synthesis for applications such as voice assistants, automated phone systems, and more.\n",
      "9. **Image and Video Generation**: Generative AI can be used to generate images and videos that are indistinguishable from those created by humans. This has applications in fields such as entertainment, advertising, and education.\n",
      "10. **Business Process Automation**: Generative AI can be used to automate business processes such as bookkeeping, accounting, and more, freeing up staff to focus on higher-value tasks.\n",
      "\n",
      "Some specific examples of businesses using generative AI include:\n",
      "\n",
      "* **Amazon** uses generative AI to personalize product recommendations for customers\n",
      "* **Google** uses generative AI to improve its search results and recommend relevant content to users\n",
      "* **Microsoft** uses generative AI to power its chatbot platform, which provides customer support and answers frequently asked questions\n",
      "* **Netflix** uses generative AI to generate personalized content recommendations for its subscribers\n",
      "\n",
      "These are just a few examples of the many business applications of generative AI. As the technology continues to evolve, we can expect to see even more innovative use cases emerge across various industries.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: AI-generated content such as videos, images, music, and text can be used for brand marketing, advertising, and entertainment.\n",
      "2. **Product Design and Development**: Generative models can help design and develop new products, such as 3D models, furniture designs, or even fashion clothing.\n",
      "3. **Customer Service**: AI-powered chatbots and virtual assistants can use generative models to generate responses to customer inquiries, providing personalized support.\n",
      "4. **Marketing and Advertising**: Generative AI can be used to create personalized ads, product recommendations, and social media content that resonates with target audiences.\n",
      "5. **Finance and Banking**: Generative models can help analyze and optimize financial data, generate credit scores, and detect fraudulent transactions.\n",
      "6. **Healthcare**: Machine Learning algorithms can analyze medical images and identify abnormalities, helping doctors make diagnoses more accurately.\n",
      "7. **Supply Chain Management**: AI-assisted predictive analytics can predict demand fluctuations, optimize logistics, and improve supply chain efficiency.\n",
      "8. **Human Resources (HR)**: Generative models can be used for recruitment, talent matching, and employee performance forecasting.\n",
      "\n",
      "Generative AI also has numerous applications in the creative industries, such as:\n",
      "\n",
      "1. **Music Composition**: AI music generation tools create new music tracks, beats, or even entire albums.\n",
      "2. **Art Creation**: AI-generated art, images, and designs can be used for advertising, branding, and entertainment purposes.\n",
      "3. **Scriptwriting and Storytelling**: Generative models can help writers generate storylines, dialogues, and character ideas.\n",
      "\n",
      "Additionally, generative AI has significant implications in the education sector:\n",
      "\n",
      "1. **Personalized Learning Paths**: AI-generated adaptive learning systems create personalized learning paths for students based on their abilities and learning styles.\n",
      "2. **Intelligent Tutoring Systems**: Generative models can help develop interactive, adaptive educational tools that provide real-time feedback to students.\n",
      "\n",
      "Generative AI has also opened up new opportunities in the field of robotics and automation:\n",
      "\n",
      "1. **Robotic Process Automation (RPA)**: AI-powered RPA tools automate repetitive tasks, improving efficiency and productivity.\n",
      "2. **AI-aided Human Augmentation**: Generative models can help human workers augment their capabilities by automating or enhancing specific tasks.\n",
      "\n",
      "These are just a few examples of the many business applications of generative AI. As the technology continues to evolve, we can expect even more innovative solutions across various industries.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## Are you confused about why that works?\n",
    "\n",
    "It seems strange, right? We just used OpenAI code to call Ollama?? What's going on?!\n",
    "\n",
    "Here's the scoop:\n",
    "\n",
    "The python class `OpenAI` is simply code written by OpenAI engineers that makes calls over the internet to an endpoint.  \n",
    "\n",
    "When you call `openai.chat.completions.create()`, this python code just makes a web request to the following url: \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "Code like this is known as a \"client library\" - it's just wrapper code that runs on your machine to make web requests. The actual power of GPT is running on OpenAI's cloud behind this API, not on your computer!\n",
    "\n",
    "OpenAI was so popular, that lots of other AI providers provided identical web endpoints, so you could use the same approach.\n",
    "\n",
    "So Ollama has an endpoint running on your local box at http://localhost:11434/v1/chat/completions  \n",
    "And in week 2 we'll discover that lots of other providers do this too, including Gemini and DeepSeek.\n",
    "\n",
    "And then the team at OpenAI had a great idea: they can extend their client library so you can specify a different 'base url', and use their library to call any compatible API.\n",
    "\n",
    "That's it!\n",
    "\n",
    "So when you say: `ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "Then this will make the same endpoint calls, but to Ollama instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling 369ca498f347: 100% ▕██████████████████▏  387 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd: 100% ▕██████████████████▏  148 B                         \u001b[K\n",
      "pulling a85fe2a2e58e: 100% ▕██████████████████▏  487 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I need to figure out what the user is asking for here. They asked me to provide definitions of some core concepts behind Large Language Models (LLMs), specifically focusing on neural networks, attention mechanisms, and transformers. Hmm. Since they included both \"LLMs\" and \"transformer,\" maybe I should also consider other components that define LLMs.\n",
      "\n",
      "Wait, the user probably wants a detailed explanation of these three main areas: neural network architecture, attention mechanisms, and transformers within LLMs. They might be someone with an interest in AI or machine learning, perhaps looking to understand how these technologies work together.\n",
      "\n",
      "Let me break it down. First, neural networks are computational models inspired by the human brain. They consist of layers that process information, each containing individual units called neurons. These networks learn from data and can model complex patterns. In LLMs, these networks might be used in various ways, like language modeling or generation, and they typically have multiple heads to capture different roles.\n",
      "\n",
      "Attention mechanisms are a crucial component that allows models to focus on specific parts of the input data. For example, when translating words, an attention mechanism helps the model concentrate on certain features of each word it's processing. This improves translation quality by leveraging contextual awareness without duplicating manual rules.\n",
      "\n",
      "The transformer architecture stands out because it uses self-attention, where each layer processes information through multiple heads simultaneously. In a multi-head setup with layers, it processes different parts of the input in parallel. For NLP tasks, like text generation, transformers can be stacked to form models with large capacity and efficient training. This makes them suitable for generating text based on inputs.\n",
      "\n",
      "Putting it all together, I should explain how neural networks function within LLMs, including their processing mechanisms. Attention is about context-aware understanding, while the transformer provides parallel computation through multi-head layers. Together, these components enable LLMs to create rich and accurate models of language.\n",
      "</think>\n",
      "\n",
      "Certainly! Large Language Models (LLMs), such as those developed by models like ChatGPT, are advanced beyond traditional neural networks due to their ability to understand text across complex boundaries between human languages. The core concepts that define LLMs include **neural network architectures**, **attention mechanisms**, and the **transformer architecture**. Here's a detailed explanation of these components:\n",
      "\n",
      "### 1. Neural Network Architecture\n",
      "\n",
      "Neural networks are computational models inspired by the biological neural systems of the brain. They consist of layers of interconnected nodes (neurons) that process information through multiple iterations, each transformation being performed by individual layers.\n",
      "\n",
      "- **Input Layer**: Collects raw data or features extracted from text.\n",
      "- **Hidden Layers**: Process information through parallel computation. Each layer applies an array of weights and activation functions to the input, producing a \"feature vector\" representing the input's characteristics.\n",
      "- **Output Layer**: Represents the model's final prediction or analysis.\n",
      "\n",
      "LLMs combine multiple layers, with attention mechanisms processing each word simultaneously during inference due to their inherent parallelism. For text modeling, LLMs are trained on vast datasets from large collections of books or web pages, often using gradient descent for optimization.\n",
      "\n",
      "### 2. Attention Mechanisms\n",
      "\n",
      "Attention in LLMs enables a model to focus on specific parts of the input data when making predictions. Each \"head\" in an attention mechanism calculates a vector representing the model's attention span across the provided context.\n",
      "\n",
      "- **Context Vector**: A concatenated representation of all provided text.\n",
      "- **Output Weights**: Calculate the final output weights based on the contexts and heads considered.\n",
      "- **Softmax Function**: Translates output vectors into probability distributions, allowing the model to make predictions while considering contextual relevance.\n",
      "\n",
      "### 3. Transformer Architecture\n",
      "\n",
      "A key component in most modern LLMs is the transformer architecture, introduced by Vaswani et al. (2017). The system uses self-attention across all layers and processes input through multiple steps at a time.\n",
      "\n",
      "- **Multi-Head Self-Attention**: Each layer applies a separate set of attention heads. This involves several linear projections or convolutional neural networks to process the transformed data.\n",
      "- **Layer Normalization**: A technique that helps stabilize training by normalizing activations before applying layer operations.\n",
      "\n",
      "This architecture allows transformers to parallelize information processing across layers, making them highly efficient. As LLMs are composed of multiple transformer layers, they can generate text in parallel and achieve high efficiency.\n",
      "\n",
      "These concepts collectively enable LLMs to model complex linguistic patterns beyond traditional neural networks, providing unparalleled capabilities in natural language generation, translation, and summarization.\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Website Summary**\n",
      "=====================\n",
      "\n",
      "### Overview\n",
      "The website belongs to Edward Donner, the co-founder and CTO of Nebula.io. The platform focuses on applying AI to help people discover their potential and pursue their reason for being.\n",
      "\n",
      "### Products and Services\n",
      "* Nebula.io: a product used by recruiters to source, understand, engage and manage talent.\n",
      "* Untapt: an AI startup acquired in 2021.\n",
      "\n",
      "### Recent News/Announcements\n",
      "* **The Complete Agentic AI Engineering Course**: announced on April 21, 2025.\n",
      "* **LLM Workshop - Hands-on with Agents - resources**: announced on December 21, 2024.\n",
      "* **Mastering AI and LLM Engineering - Resources**: announced on November 13, 2024.\n",
      "\n",
      "### Other Information\n",
      "The website includes information about Edward Donner's personal interests (DJing, amateur electronic music production) as well as links to his professional profiles (LinkedIn, Twitter, Facebook).\n"
     ]
    }
   ],
   "source": [
    "# A class to represent a Webpage\n",
    "# If you're not familiar with Classes, check out the \"Intermediate Python\" notebook\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\"\n",
    "\n",
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt\n",
    "\n",
    "# See how this function creates exactly the format above\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]\n",
    "\n",
    "# And now: call the OpenAI API. You will get very familiar with this!\n",
    "\n",
    "# Constants\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\"\n",
    "WEBSITE_URL = \"\"\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "website = Website(\"https://edwarddonner.com\")\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model = MODEL,\n",
    "    messages = messages_for(website)\n",
    ")\n",
    "print(response.choices[0].message.content)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c872a9-df88-4a31-927d-25968a0742c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
